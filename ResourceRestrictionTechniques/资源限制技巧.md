### 资源限制技巧
#### 1）布隆过滤器用于集合的建立与查询，并可以节省大量空间（已讲）

#### 2）一致性哈希解决数据服务器的负载管理问题（已讲）

#### 3）利用并查集结构做岛问题的并行计算（已讲）

#### 4）哈希函数可以把数据按照种类均匀分流
题目一：
32位无符号整数的范围是0~4,294,967,295，
现在有一个正好包含40亿个无符号整数的文件，
可以使用最多1GB的内存，怎么找到出现次数最多的数？

思路分析：
1)32位无符号整数的范围0 ~ 4294967295
2)文件包含40亿个无符号整数
3)内存最多1G

1.使用将40亿个无符号整数的排序的方式，排序是根据数组进行排序的，在硬盘文件中如何排序
如果一定要进行排序，排序申请数组的内存空间 = 40亿个无符号整数，一个int类型占4个字节，一共占160亿个字节，也就是16G，而题目限制1G内存
所以排序这个思路被堵死了

2.使用哈希表的方式
哈希表使用内存和40亿个无符号整数个数无关，和出现多少个不相同的整数有关

极好情况：
如果40亿个无符号整数都是相同的数，那么哈希表只有一条记录，并且40亿个无符号整数都是int类型，所以key占4个字节，value占4个字节
哈希表这一条记录占8个字节

极差情况：
如果40亿个无符号整数都是不相同的数，那么哈希表有40亿条记录，并且40亿个无符号整数都是int类型，所以key占4个字节，value占4个字节
哈希表这40亿条记录占40亿 * 8(一条记录占8字节) = 320亿字节 = 32G

其它情况：
哈希表key和value占用完空间，还有其它的开销，比如：内部还有数据库结构连接的索引开销，所以题目限制内存1G是肯定不行的，哈希表会爆掉
所以哈希表这个思路被堵死了

3.
1)1G内存，并且哈希表的key和value都是int烈性，那么哈希表的一条记录就是8个字节(key 4个字节，value 4个字节)，哈希表就能存储1亿2千5百万条
除去哈希表中数据库结构连接的索引等其它数据意外，假设哈希表只能存储1千万条记录

2)文件包含40亿个无符号整数，40亿 / 1千万 = 400

3)对40亿个无符号整数的每一个整数计算哈希值，然后对400进行取模，
举例：
假设整数17计算出哈希值，模400之后，结果为3，那么将整数17存放到3号文件
假设整数29056计算出哈希值，模400之后，结果为173，那么将整数29056存放到173号文件

4)哈希函数的性质：相同的输入一定导致相同的输出，模完之后，一定也是相同的一个，所以每个文件中，同一个整数只会存放在同一个文件

5)这样就有了400个文件： 0号文件 ~ 399号文件
不清楚每个文件的个数是多少，但是种数绝对不会超过1千万个，即使是超过也只会超过一点点
举例：
假设有1000条数据，每一个数据计算出哈希值之后对10进行取模，最后的结果肯定在0 ~ 9范围内

0   1   2   3   4   5   6   7   8   9
100 100 100 100 100 100 100 100 100 100
每一个得到的记录都在100条左右，也就是100的上下浮动之间，这就是哈希函数的性质

同一种数不会分到多个文件中去
哈希函数是有均匀性的，取模400之后仍然有均匀性，最差情况下，40亿个无符号整数有40亿个种数，也会几乎均分的存放到各自的文件中去

6)使用哈希表对0号文件中求出现次数最多的数，然后在将哈希表的空间释放，再对1号文件中求出现次数最多的数，依次类推
就能求出400个文件，各自文件中出现次数最多的数No1，然后最后求出这400个No1中出现次数最多的

7)利用哈希分流
假设面试官给你一个大文件，有内存限制
要求统计大文件的某些内容，但是发现使用内存做哈希表或者其它记录结构搞这个大文件会爆掉
这时候，就可以通过大文件通过哈希函数计算出哈希值模一个值，发送到0号服务器上，下一个发送到1号服务器，依次类推
如果服务器上还是过大，服务器可以使用第二个哈希函数，在这台服务器上分成小文件，

想要解决的问题：一直分，分到内存限制的情况下也能满足要求为止

8)题目一总结：哈希来，哈希去
假设N种不同的数，对每一种数计算哈希值对M进行取模，一共分成0号文件，1号文件，...，M - 1号文件，总共M个文件
每个文件的种数都差不多有N / M种数

哈希表不怕一种数字出现很多次，因为这个数字对应的这条记录的key值不变，占4个字节，value值++，值再++，也只占4个字节，
出现再多次，这条记录也只占8个字节
同一种数不会分到多个文件中去，因为这个数计算出的哈希值不可能改变，那么这个数永远只会分配到同一个文件中





题目二：
32位无符号整数的范围是0~4,294,967,295，
现在有一个正好包含40亿个无符号整数的文件，
所以在整个范围中必然存在没出现过的数。
可以使用最多1GB的内存，怎么找到所有未出现过的数？
【进阶】
内存限制为 3KB，但是只用找到一个没出现过的数即可

1.使用哈希Set结构的方式
Set的key表示数出没出现过，一条记录只有key，key占4个字节，这条记录就占8个字节
极差情况下：
40亿个数，每一个数都不相同，都没有出现过，那么Set集合每条记录4个字节，那么至少需要40亿 * 4 = 160亿字节 = 16G
循环遍历从0 ~ 42亿，虽然可以实现，但是内存16G超过限制的1G
#### 5）位图解决某一范围上数字的出现情况，并可以节省大量空间
2.使用位图的方式
使用表示位数的数组，数组的索引存储每一位，32位无符号整数的范围0 ~ 2的32次方 - 1，一共2的32次方个数
准备2的32次方的位图，8位表示1个字节，2的32次方的位图一共占用2的32次方 / 8的字节 = 2的29次方个字节 = 536870912 / 1000000000
不超过600M，没有超出题目的限制内存1G ，并且位图上的值如果是0就表示没有出现过，1表示出现过

所以空间够用，但前提是bit[]
536870912 / 32 = 16777216 就是要申请的int[]内存空间
int[] bits = new int[16777216]; 

详见BitMap类

#### 6）利用分段统计思想、并进一步节省大量空间
题目二进阶：
32位无符号整数的范围是0~4,294,967,295，
现在有一个正好包含40亿个无符号整数的文件，
所以在整个范围中必然存在没出现过的数。
内存限制为 3KB，但是只用找到一个没出现过的数即可

32位无符号整数范围0 ~ 2的32 - 1，一共2的32次方个数
题目内存限制3KB，4个字节组成int类型，那么3KB / 4 = 750，离750最近并且比750小的是2的5次方 -> 512，
所以int[] arr申请512的长度即可，也就说利用分段统计思想将0~2的32次方-1的范围分成512段
每一段的范围都是8,388,608，arr[0] 统计 0 ~ 8388607，arr[1] 统计 8388608 ~ 16777215，依次类推

int[] arr能够容纳2的32次方 -> 4294967296个数，而文件只包含40亿个数，所以一定会有一个分段范围不够的8388608
题目要求只需要找到一个没出现过的数，又能够找到不满的范围，只需要在这个不满8388608的范围上找没出现过的数就行

如何在这个不满8388608的范围上找没出现过的数就行，将这个范围继续分成512段，肯定还有更小的不满的范围，再将这个更小的不满的范围分成512段
依次类推，不需要分多少次，就能找到

题目二再次进阶：
32位无符号整数的范围是0~4,294,967,295，
现在有一个正好包含40亿个无符号整数的文件，
所以在整个范围中必然存在没出现过的数。
只允许有几个有限的变量，找到一个没出现过的数

使用L表示0位置开始，R表示2的32次方-1结束，mid在中间
左侧0 ~ mid，右侧mid+1 ~ 2的32次方-1，哪一侧不够2的31次方，哪一侧就继续二分

题目三：
有一个包含100亿个URL的大文件，假设每个URL占用64B，
请找出其中所有重复的URL
【补充】
某搜索公司一天的用户搜索词汇是海量的(百亿数据量)，
请设计一种求出每天热门Top100词汇的可行办法

1.使用布隆过滤器的方式，但是会有失误率

2.使用哈希函数的方式，因为同一个URL只会出现在同一个文件中
大文件的URL使用哈希函数计算分到小文件中，如果小文件还不够，使用第二个哈希函数将小文件分成更小的文件，检查更小文件中有没有重复的URL
因为同一个URL只会出现在同一个文件中

题目四：
32位无符号整数的范围是0~4294967295，
现在有40亿个无符号整数，
可以使用最多1GB的内存，
找出所有出现了两次的数。


1位表示0 ~ 2的32次方 - 1的范围，需要536M

使用两位表示数出现的次数：00表示出现0次，01表示出现1次，10表示出现2次，11表示出现3次及3次以上
第0位和第1位表示0出现的次数  
第2位和第3位表示1出现的次数
第4位和第5位表示2出现的次数
第6位和第7位表示3出现的次数
...
一开始所有的词频都是00，第一次发现的时候设置为01，第二次发现的时候设置为10，第三次发现的时候设置为11，第四次发现的时候不管
做完每一个数的词频统计之后，谁的状态是10的，谁就是出现了两次

2的32次方 / 8(记录：key 4个字节，value 4个字节) = 536870912Byte -> 536M * 2超出了内存限制1G

统计左边一半：2的31次方，看看 哪些数出现了两次，统计右边一半：2的31次方，看看哪些数出现了两次
位图 + 分段统计
如果担心哈希表会爆掉，先统计左边一半哪些数出现两次，再统计右边一半哪些数出现两次

题目五：
32位无符号整数的范围是0~4294967295，现在有40亿个无符号整数
可以使用最多3K的内存，怎么找到这40亿个整数的中位数？

32位无符号整数范围0 ~ 2的32 - 1，一共2的32次方个数
题目内存限制3KB，4个字节组成int类型，那么3KB / 4 = 750，离750最近并且比750小的是2的5次方 -> 512，
所以int[] arr申请512的长度即可，也就说利用分段统计思想将0~2的32次方-1的范围分成512段
每一段的范围都是8,388,608，arr[0] 统计 0 ~ 8388607，arr[1] 统计 8388608 ~ 16777215，依次类推
int[] arr = new int[512];

一共40亿个数，找第20亿个数，假设第1段出现的数词频a，1亿个，范围最低的出现一亿个，整体找第20亿个，上中位数绝对不是第1段范围上的任
何一个数，a词频 + 下一段的词频统计b，加完的结果假设5亿个，整体找第20亿个，所以上中位数既不来自第1段，也不来自第2段
依次把词频往下加，谁刚到第20亿个，或者刚超出20亿，上中位数一定来自于这段范围

举例1：
[第1段][第2段][第3段]...[第170段][第171段]       整体第20亿个
                         19亿     23亿
第1段 +第2段 + 第171段的词频统计达到23亿，那么要找的上中位数在第171段的数字中第1亿个，因为前面已经有19个词频统计个数
在第171段范围上，谁是第1亿个的数，谁就是整体的第20亿个数

举例2：
范   围：1 ~ 9 10 - 19 20 - 29 30 - 39
段   数：[ 1 ] [  2  ] [  3  ] [  4  ]       整体第200个
词频统计：17个   33个     67个     150个
上中位数肯定不在1 ~ 9范围上， 第1段 + 第2段 = 50个，上中位数也不在10 ~ 19范围上，第1段 + 第2段 + 第3段 = 117个，
上中位数也不在20 ~ 29范围上，第1段 + 第2段 + 第3段 + 第4段 = 267个，超过第200个，所以上中位数一定在30 ~ 39范围上
那么30 ~ 39范围上第几个数是整体第200个数？前面第1段+第2段+第3段，也就是1 ~ 29范围上已经词频统计117个了，要的是第200个
所以200 - 117 = 83，在30 ~ 39范围上第83个数就是整体第200个数，也就是整体的上中位数


#### 7）利用堆、外排序来做多个处理单元的结果合并
外排序：不使用堆，每次都遍历来做，效率低
题目六：
32位无符号整数的范围是0~4294967295，
有一个10G大小的文件，每一行都装着这种类型的数字，
整个文件是无序的，给你5G的内存空间，
请你输出一个10G大小的文件，就是原文件所有数字排序的结果

怎样利用5G大小的内存输出10G大小的经过所有数字排序之后的原文件
1.使用大根堆的方式
10G大小的文件，假设有一个只能装3条记录的容器

10G大小的文件                    只能容纳3条记录的容器
数字                            词频统计，统计次数
5                                    5, 1 -> 已更新
5                                    5, 2 -> 已删除
3                                    3, 1 -> 已更新
9                                    9, 1 -> 已更新
9                                    9, 2 -> 已删除
4                               此时容器的最大值9，9比4大，删除9，加入4 -> 4, 1
3                                    3, 2 
1                               此时容器的最大值5，5比1大，删除5，加入1 -> 1, 1 
当遍历完所有的文件的时候，最小的前3条记录，及其出现的次数都正确统计了

举例：
10G大小的文件                    只能容纳3条记录的容器                
                                 词频统计，统计次数
                                     1, 1000
                                     6, 90000
                                    13, 150000
1、6、13一定是最小的前3条记录
生成 所有数字排序后的10G大小的文件
1
输出1000次
6
输出90000次
13
输出150000次
此时使用变量t 记录容器中最大的值 -> t = 13，然后容器空间释放，再次遍历一遍10G大小的文件，只要是 <= t的数直接略过
就能得到13往上最小的前3条记录

10G大小的文件                    只能容纳3条记录的容器              
                                  词频统计，统计次数
                                     26, 500000
                                     27, 540000
                                     49, 3
26、27、49一定是最小的前3条记录
所有数字排序后的10G大小的文件继续输出
26
输出500000次
27
输出540000次
49
输出3次

此时使用变量t 记录容器中最大的值 -> t = 49，然后容器空间释放，再次遍历一遍10G大小的文件，只要是 <= t的数直接略过
就能得到49往上最小的前3条记录

这个容器就是大根堆
此时容器就不止3条记录了，题目给了5G的内存，一条记录key是int类型占4个字节，value保险一点是long类型占8个字节，这条记录占12个字节
5G大小的容器：大根堆能够存储 5000000000Byte / 12Byte = 416666666条记录，
10G大小的原文件：一共10000000000Byte / 12Byte = 833333333条记录，总共遍历该原文件2遍就能将所有的数排序之后进行输出

最保险的5G大小的容器：大根堆只能存储416666666 / 10 = 41666666条记录
总共遍历该原文件20多遍就能将10G大小的原文件所有的数排序之后进行输出

循环结束的条件就是此时的大根堆已经收集不到该堆的大小了，说明原文件已经没有可以收集的数了，停！

题目七：
请你求出一个大文件中，出现次数最多的前100名
如果第100名有多个，或者有多个并列的第99名，已经超过了100名，
只需要告诉我任意的前100名，也就是并列的情况下只选择前100个

1.
大文件使用哈希函数拆分成多个小文件，求每个小文件的次数最多的前Top100，
举例：
第1个小文件 第2个小文件 第3个小文件 求大文件的前3名
a : 17       x : 23    z : 9
b : 16       y : 21    k : 9
c : 10       p : 6     f : 9

如果不使用堆，那么就是外排序
a 和 x 和 z比较第一名，选出x，然后a 和 y 和 z比较，选出y，得出前3名：a，x，y

如果使用大根堆
将a b c在第1个文件中组成大根堆
将x y p在第2个文件中组成大根堆
将z k f在第3个文件中组成大根堆

抽取出每个大根堆的堆顶元素，然后组成总的大根堆，这个总的大根堆的堆顶就是整个大文件的Top1，然后弹出这个Top1 : x，记录x在第2个小文件
，将第2个小文件的x的下一个元素y添加到大根堆中，重新调整出此时大根堆的Top1，弹出这个Top2 : y，记录y在第2个小文件，将第2个小文件的y
的下一个元素p添加到大根堆中，周而复始，直到凑够前3名

#### 资源限制技巧的总结
技巧掌握好之后，对面试官的时候，该问什么就问什么，别觉得他给你的就是比较全的条件

资源限制类题目一上来就会说的模棱两可，等着你问

#### 资源限制类技巧和面试题的区别
只有问面试官，逐渐把限制问清楚，才能提出解决方案



